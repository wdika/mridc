<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mridc.core.classes.modelPT &mdash; mridc v.0.0.1 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->

        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
</head>

<body class="wy-body-for-nav">
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> mridc
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Documentation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules.html">mridc</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">mridc</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>mridc.core.classes.modelPT</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">

  <h1>Source code for mridc.core.classes.modelPT</h1><div class="highlight"><pre>
<span></span><span class="c1"># encoding: utf-8</span>
<span class="n">__author__</span> <span class="o">=</span> <span class="s2">&quot;Dimitrios Karkalousos&quot;</span>

<span class="c1"># Taken and adapted from: https://github.com/NVIDIA/NeMo/blob/main/nemo/core/classes/modelPT.py</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">path</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">hydra</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">omegaconf</span> <span class="kn">import</span> <span class="n">DictConfig</span><span class="p">,</span> <span class="n">OmegaConf</span><span class="p">,</span> <span class="n">open_dict</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning</span> <span class="kn">import</span> <span class="n">LightningModule</span><span class="p">,</span> <span class="n">Trainer</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities</span> <span class="kn">import</span> <span class="n">rank_zero_only</span>

<span class="kn">from</span> <span class="nn">mridc.core.classes.common</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ModelPT&quot;</span><span class="p">]</span>

<span class="kn">import</span> <span class="nn">mridc.core.optim</span>
<span class="kn">from</span> <span class="nn">mridc</span> <span class="kn">import</span> <span class="n">package_info</span>
<span class="kn">from</span> <span class="nn">mridc.core.connectors.save_restore_connector</span> <span class="kn">import</span> <span class="n">SaveRestoreConnector</span>
<span class="kn">from</span> <span class="nn">mridc.utils</span> <span class="kn">import</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="nn">mridc.utils.app_state</span> <span class="kn">import</span> <span class="n">AppState</span>
<span class="kn">from</span> <span class="nn">mridc.utils.get_rank</span> <span class="kn">import</span> <span class="n">is_global_rank_zero</span>
<span class="kn">import</span> <span class="nn">mridc.utils</span>


<div class="viewcode-block" id="ModelPT"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT">[docs]</a><span class="k">class</span> <span class="nc">ModelPT</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">,</span> <span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Interface for Pytorch-lightning based mridc models&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">DictConfig</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="n">Trainer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Base class from which all mridc models should inherit</span>

<span class="sd">        Internal global flags that determine core functionality of ModelPT.</span>
<span class="sd">        _MODEL_IS_RESTORED:</span>
<span class="sd">            This flag determines the context of the model - whether the model is currently being</span>
<span class="sd">            restored or not.</span>
<span class="sd">            -   When set, it can be assumed that the model&#39;s will disable all automatic methods -</span>
<span class="sd">                setup_training_data(), setup_validation/test_data() and their multi equivalents.</span>
<span class="sd">            -   If a model is being restored from a archive file (tarfile), it can be assumed that</span>
<span class="sd">                under this context, the cwd is *inside* the tarfile itself.</span>
<span class="sd">        _MODEL_RESTORE_PATH:</span>
<span class="sd">            A string path to a a file from which the model is being restored.</span>
<span class="sd">            This file can either be a PyTorch Lightning Checkpoint, or a archive (tarfile) that contains</span>
<span class="sd">            artifact objects.</span>
<span class="sd">            If it is an archive file, during restoration, the cwd will be temporarily moved to inside the</span>
<span class="sd">            archive itself.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        cfg: configuration object. The cfg object should have (optionally) the following sub-configs:</span>
<span class="sd">            - train_ds - to instantiate training dataset</span>
<span class="sd">            - validation_ds - to instantiate validation dataset</span>
<span class="sd">            - test_ds - to instantiate testing dataset</span>
<span class="sd">            - optim - to instantiate optimizer with learning rate scheduler</span>
<span class="sd">        trainer: Pytorch Lightning Trainer instance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">trainer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">Trainer</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;trainer constructor argument must be either None or pytorch_lightning.Trainer. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;But got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># set global vars in AppState</span>
        <span class="n">app_state</span> <span class="o">=</span> <span class="n">AppState</span><span class="p">()</span>

        <span class="c1"># Convert config to a DictConfig</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">convert_model_config_to_dict_config</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>

        <span class="c1"># Convert config to support Hydra 1.0+ instantiation</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">maybe_update_config_version</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Creating model config node is forbidden due to collision problem when loading from checkpoint.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;target&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">:</span>
            <span class="c1"># This is for Jarvis service.</span>
            <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="n">cfg</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">.</span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__module__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
            <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;mridc_version&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">open_dict</span><span class="p">(</span><span class="n">cfg</span><span class="p">):</span>
                <span class="n">cfg</span><span class="o">.</span><span class="n">mridc_version</span> <span class="o">=</span> <span class="n">package_info</span><span class="o">.</span><span class="n">__version__</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">cfg</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="s2">&quot;cfg&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_dl</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validation_dl</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_dl</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_param_groups</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scheduler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">trainer</span>  <span class="c1"># reference required for self.*_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span>  <span class="c1"># alias for backward compatibility</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save_restore_connector</span> <span class="o">=</span> <span class="n">SaveRestoreConnector</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_model_guid</span><span class="p">()</span>

        <span class="c1"># Set device_id in AppState</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">app_state</span><span class="o">.</span><span class="n">device_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_model_being_restored</span><span class="p">():</span>
            <span class="k">if</span> <span class="s2">&quot;train_ds&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">train_ds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">setup_training_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">train_ds</span><span class="p">)</span>

            <span class="k">if</span> <span class="s2">&quot;validation_ds&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">validation_ds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">setup_multiple_validation_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">validation_ds</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="k">if</span> <span class="s2">&quot;test_ds&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">test_ds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">setup_multiple_test_data</span><span class="p">(</span><span class="n">test_data_config</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;train_ds&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">train_ds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() &quot;</span>
                    <span class="s2">&quot;method and provide a valid configuration file to setup the train data loader.</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Train config : </span><span class="se">\n</span><span class="si">{</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_yaml</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">train_ds</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>  <span class="c1"># type: ignore</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;validation_ds&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">validation_ds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;If you intend to do validation, please call the ModelPT.setup_validation_data() or &quot;</span>
                    <span class="s2">&quot;ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to &quot;</span>
                    <span class="s2">&quot;setup the validation data loader(s). </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Validation config : </span><span class="se">\n</span><span class="si">{</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_yaml</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">validation_ds</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>  <span class="c1"># type: ignore</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;test_ds&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">test_ds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method &quot;</span>
                    <span class="s2">&quot;and provide a valid configuration file to setup the test data loader(s).</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Test config : </span><span class="se">\n</span><span class="si">{</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_yaml</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">test_ds</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>  <span class="c1"># type: ignore</span>
                <span class="p">)</span>

        <span class="c1"># ModelPT wrappers over subclass implementations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_step</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">wrap_training_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

<div class="viewcode-block" id="ModelPT.__init_subclass__"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.__init_subclass__">[docs]</a>    <span class="k">def</span> <span class="nf">__init_subclass__</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;This method is called when a subclass is created.&quot;&quot;&quot;</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_save_restore_connector</span> <span class="o">=</span> <span class="n">SaveRestoreConnector</span><span class="p">()</span></div>

<div class="viewcode-block" id="ModelPT.register_artifact"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.register_artifact">[docs]</a>    <span class="k">def</span> <span class="nf">register_artifact</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">verify_src_exists</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Register model artifacts with this function. These artifacts (files) will be included inside .mridc file when</span>
<span class="sd">        model.save_to(&quot;model.mridc&quot;) is called.</span>

<span class="sd">        How it works:</span>
<span class="sd">            1. It always returns existing absolute path which can be used during Model constructor call EXCEPTION: \</span>
<span class="sd">            src is None or &quot;&quot; in which case nothing will be done and src will be returned</span>
<span class="sd">            2. It will add (config_path, model_utils.ArtifactItem()) pair to self.artifacts</span>

<span class="sd">        If &quot;src&quot; is local existing path, then it will be returned in absolute path form.</span>
<span class="sd">        elif &quot;src&quot; starts with &quot;mridc_file:unique_artifact_name&quot; .mridc will be untarred to a temporary folder \</span>
<span class="sd">        location and an actual existing path will be returned else an error will be raised.</span>

<span class="sd">        WARNING: use .register_artifact calls in your models&#39; constructors.</span>
<span class="sd">        The returned path is not guaranteed to exist after you have exited your model&#39;s constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        config_path: Artifact key. Usually corresponds to the model config.</span>
<span class="sd">        src: Path to artifact.</span>
<span class="sd">        verify_src_exists: If set to False, then the artifact is optional and register_artifact will return None \</span>
<span class="sd">        even if src is not found. Defaults to True.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        If src is not None or empty it always returns absolute path which is guaranteed to exist during model \</span>
<span class="sd">        instance life.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">src</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">src</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">src</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;artifacts&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">artifacts</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">ArtifactItem</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">artifacts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">artifacts</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="n">config_path</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">artifacts</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;You tried to register an artifact under config key=</span><span class="si">{</span><span class="n">config_path</span><span class="si">}</span><span class="s2"> but an artifact for &quot;</span>
                <span class="s2">&quot;it has already been registered.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_restore_connector</span><span class="o">.</span><span class="n">register_artifact</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_path</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">verify_src_exists</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModelPT.save_to"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.save_to">[docs]</a>    <span class="k">def</span> <span class="nf">save_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves model instance (weights and configuration) into .mridc file. You can use &quot;restore_from&quot; method to fully</span>
<span class="sd">        restore instance from .mridc file. .mridc file is an archive (tar.gz) with the following:</span>
<span class="sd">        - model_config.yaml - model configuration in .yaml format. You can deserialize this into cfg argument for \</span>
<span class="sd">         model&#39;s constructor</span>
<span class="sd">        - model_wights.ckpt - model checkpoint</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Path to .mridc file where model instance should be saved.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">maybe_make_save_dir</span><span class="p">(</span><span class="n">_path</span><span class="p">:</span> <span class="s2">&quot;Path&quot;</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Creates directory if it does not exist&quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">_path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                <span class="n">_path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">save_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span>  <span class="c1"># type: ignore</span>
        <span class="n">app_state</span> <span class="o">=</span> <span class="n">AppState</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">app_state</span><span class="o">.</span><span class="n">model_parallel_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">app_state</span><span class="o">.</span><span class="n">model_parallel_size</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_save_restore_connector</span><span class="p">)</span> <span class="ow">is</span> <span class="n">SaveRestoreConnector</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Default mridc SaveRestoreConnector will not work in model parallel mode. You should use a &quot;</span>
                    <span class="s2">&quot;connector which supports model parallel mode. You can also use a custom one.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">app_state</span><span class="o">.</span><span class="n">data_parallel_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">maybe_make_save_dir</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">))</span>
            <span class="c1"># connector checks for ranks properly, no need to check here</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_save_restore_connector</span><span class="o">.</span><span class="n">save_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">save_path</span><span class="p">))</span>  <span class="c1"># downstream tasks expect str, not Path</span>
        <span class="k">elif</span> <span class="n">is_global_rank_zero</span><span class="p">():</span>
            <span class="n">maybe_make_save_dir</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_save_restore_connector</span><span class="o">.</span><span class="n">save_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">save_path</span><span class="p">))</span>  <span class="c1"># downstream tasks expect str, not Path</span></div>

<div class="viewcode-block" id="ModelPT.restore_from"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.restore_from">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">restore_from</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">restore_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">override_config_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">OmegaConf</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">return_config</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">save_restore_connector</span><span class="p">:</span> <span class="n">SaveRestoreConnector</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Restores model instance (weights and configuration) from .mridc file.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        restore_path: path to .mridc file from which model should be instantiated override_config_path: path to a \</span>
<span class="sd">        yaml config that will override the internal config file or an OmegaConf/DictConfig object representing the \</span>
<span class="sd">        model config.</span>
<span class="sd">        map_location: Optional torch.device() to map the instantiated model to a device. By default (None), it will \</span>
<span class="sd">        select a GPU if available, falling back to CPU otherwise.</span>
<span class="sd">        strict: Passed to load_state_dict. By default, True.</span>
<span class="sd">        return_config: If set to true, will return just the underlying config of the restored model as an \</span>
<span class="sd">        OmegaConf/DictConfig object without instantiating the model.</span>
<span class="sd">        trainer: Optional, a pytorch lightning Trainer object that will be forwarded to the instantiated model&#39;s \</span>
<span class="sd">        constructor.</span>
<span class="sd">        save_restore_connector: Can be overridden to add custom save and restore logic.</span>

<span class="sd">        Example</span>
<span class="sd">        -------</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            model = mridc.collections.asr.models.EncDecCTCModel.restore_from(&#39;asr.mridc&#39;)</span>
<span class="sd">            assert isinstance(model, mridc.collections.asr.models.EncDecCTCModel)</span>


<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        An instance of type cls or its underlying config (if return_config is set).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">save_restore_connector</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_restore_connector</span> <span class="o">=</span> <span class="n">SaveRestoreConnector</span><span class="p">()</span>

        <span class="n">restore_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">restore_path</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">restore_path</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Can&#39;t find </span><span class="si">{</span><span class="n">restore_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">app_state</span> <span class="o">=</span> <span class="n">AppState</span><span class="p">()</span>
        <span class="n">app_state</span><span class="o">.</span><span class="n">model_restore_path</span> <span class="o">=</span> <span class="n">restore_path</span>

        <span class="bp">cls</span><span class="o">.</span><span class="n">update_save_restore_connector</span><span class="p">(</span><span class="n">save_restore_connector</span><span class="p">)</span>
        <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_save_restore_connector</span><span class="o">.</span><span class="n">restore_from</span><span class="p">(</span>
            <span class="bp">cls</span><span class="p">,</span> <span class="n">restore_path</span><span class="p">,</span> <span class="n">override_config_path</span><span class="p">,</span> <span class="n">map_location</span><span class="p">,</span> <span class="n">strict</span><span class="p">,</span> <span class="n">return_config</span><span class="p">,</span> <span class="n">trainer</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="n">ModelPT</span><span class="p">):</span>
            <span class="n">instance</span><span class="o">.</span><span class="n">_save_restore_connector</span> <span class="o">=</span> <span class="n">save_restore_connector</span>
        <span class="k">return</span> <span class="n">instance</span></div>

<div class="viewcode-block" id="ModelPT.load_from_checkpoint"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.load_from_checkpoint">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load_from_checkpoint</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">checkpoint_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">hparams_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads ModelPT from checkpoint, with some maintenance of restoration.</span>
<span class="sd">        For documentation, please refer to LightningModule.load_from_checkpoint() documentation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">_set_model_restore_state</span><span class="p">(</span><span class="n">is_being_restored</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">checkpoint</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
                <span class="n">checkpoint_path</span><span class="o">=</span><span class="n">checkpoint_path</span><span class="p">,</span>
                <span class="o">*</span><span class="n">args</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
                <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">,</span>
                <span class="n">hparams_file</span><span class="o">=</span><span class="n">hparams_file</span><span class="p">,</span>
                <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">_set_model_restore_state</span><span class="p">(</span><span class="n">is_being_restored</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">checkpoint</span></div>

<div class="viewcode-block" id="ModelPT.setup_training_data"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.setup_training_data">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">setup_training_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data_config</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DictConfig</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;Setups data loader to be used in training.&quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="ModelPT.setup_validation_data"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.setup_validation_data">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">setup_validation_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_data_config</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DictConfig</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;Setups data loader to be used in validation.&quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="ModelPT.setup_test_data"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.setup_test_data">[docs]</a>    <span class="k">def</span> <span class="nf">setup_test_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data_config</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DictConfig</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;(Optionally) Setups data loader to be used in test.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="ModelPT.setup_multiple_validation_data"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.setup_multiple_validation_data">[docs]</a>    <span class="k">def</span> <span class="nf">setup_multiple_validation_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_data_config</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DictConfig</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;(Optionally) Setups data loader to be used in validation.&quot;&quot;&quot;</span>
        <span class="c1"># Set some placeholder overridden by helper method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_val_dl_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_names</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># preserve config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_dataset_config</span><span class="p">(</span><span class="n">dataset_name</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">val_data_config</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_multi_dataset_mode</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">resolve_validation_dataloaders</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_multi_dataset_mode</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">validation_names</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validation_dl</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_validation_dl</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">]</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">validation_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;val_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">_&quot;</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_validation_dl</span><span class="p">))]</span></div>

<div class="viewcode-block" id="ModelPT.setup_multiple_test_data"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.setup_multiple_test_data">[docs]</a>    <span class="k">def</span> <span class="nf">setup_multiple_test_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data_config</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DictConfig</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;(Optionally) Setups data loader to be used in test, with support for multiple data loaders.&quot;&quot;&quot;</span>
        <span class="c1"># Set some placeholder overridden by helper method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_dl_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_names</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_dl</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># type: ignore</span>

        <span class="c1"># preserve config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_dataset_config</span><span class="p">(</span><span class="n">dataset_name</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">test_data_config</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_multi_dataset_mode</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">resolve_test_dataloaders</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_multi_dataset_mode</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_names</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_dl</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_test_dl</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;test_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">_&quot;</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_test_dl</span><span class="p">))]</span></div>

<div class="viewcode-block" id="ModelPT.setup_optimization"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.setup_optimization">[docs]</a>    <span class="k">def</span> <span class="nf">setup_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optim_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">DictConfig</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepares an optimizer from a string name and its optional config parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        optim_config: A dictionary containing the following keys:</span>
<span class="sd">            - lr: mandatory key for learning rate. Will raise ValueError if not provided.</span>
<span class="sd">            - optimizer: string name pointing to one of the available optimizers in the registry. If not provided, \</span>
<span class="sd">            defaults to &quot;adam&quot;.</span>
<span class="sd">            - opt_args: Optional list of strings, in the format &quot;arg_name=arg_value&quot;. The list of &quot;arg_value&quot; will \</span>
<span class="sd">            be parsed and a dictionary of optimizer kwargs will be built and supplied to instantiate the optimizer.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        An instance of an optimizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_param_groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_optimizer_param_groups</span><span class="p">()</span>

        <span class="c1"># If config was not explicitly provided, use default</span>
        <span class="k">if</span> <span class="n">optim_config</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="s2">&quot;optim&quot;</span><span class="p">):</span>
            <span class="n">optim_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">optim</span>

        <span class="c1"># If config is still None, or internal config has no Optim, return without instantiation</span>
        <span class="k">if</span> <span class="n">optim_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No optimizer config provided, therefore no optimizer was created&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="c1"># Preserve the configuration</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optim_config</span><span class="p">,</span> <span class="n">DictConfig</span><span class="p">):</span>
            <span class="n">optim_config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">optim_config</span><span class="p">)</span>

        <span class="c1"># See if internal config has `optim` namespace before preservation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="s2">&quot;optim&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">optim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">optim_config</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">open_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">optim</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">optim_config</span><span class="p">)</span>

        <span class="c1"># Setup optimizer and scheduler</span>
        <span class="k">if</span> <span class="n">optim_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optim_config</span><span class="p">,</span> <span class="n">DictConfig</span><span class="p">):</span>
            <span class="n">optim_config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="n">optim_config</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Trainer wasn&#39;t specified in model constructor. Make sure that you really wanted it.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;sched&quot;</span> <span class="ow">in</span> <span class="n">optim_config</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">accumulate_grad_batches</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;We do not currently support gradient accumulation that is not an integer.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
                <span class="c1"># Store information needed to calculate max_steps</span>
                <span class="n">optim_config</span><span class="p">[</span><span class="s2">&quot;sched&quot;</span><span class="p">][</span><span class="s2">&quot;t_max_epochs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">max_epochs</span>
                <span class="n">optim_config</span><span class="p">[</span><span class="s2">&quot;sched&quot;</span><span class="p">][</span><span class="s2">&quot;t_accumulate_grad_batches&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">accumulate_grad_batches</span>
                <span class="n">optim_config</span><span class="p">[</span><span class="s2">&quot;sched&quot;</span><span class="p">][</span><span class="s2">&quot;t_limit_train_batches&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">limit_train_batches</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">accelerator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">optim_config</span><span class="p">[</span><span class="s2">&quot;sched&quot;</span><span class="p">][</span><span class="s2">&quot;t_num_workers&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">num_devices</span> <span class="ow">or</span> <span class="mi">1</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">accelerator</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;ddp_cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;ddp&quot;</span><span class="p">]:</span>
                    <span class="n">optim_config</span><span class="p">[</span><span class="s2">&quot;sched&quot;</span><span class="p">][</span><span class="s2">&quot;t_num_workers&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">num_devices</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">num_nodes</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;The lightning trainer received accelerator: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">accelerator</span><span class="si">}</span><span class="s2">. We &quot;</span>
                        <span class="s2">&quot;recommend to use &#39;ddp&#39; instead.&quot;</span>
                    <span class="p">)</span>
                    <span class="n">optim_config</span><span class="p">[</span><span class="s2">&quot;sched&quot;</span><span class="p">][</span><span class="s2">&quot;t_num_workers&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">num_devices</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">num_nodes</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">optim_config</span><span class="p">[</span><span class="s2">&quot;sched&quot;</span><span class="p">][</span><span class="s2">&quot;max_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">max_steps</span>

        <span class="c1"># Force into DictConfig from nested structure</span>
        <span class="n">optim_config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">optim_config</span><span class="p">)</span>
        <span class="c1"># Get back nested dict so we its mutable</span>
        <span class="n">optim_config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="n">optim_config</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Extract scheduler config if inside optimizer config</span>
        <span class="k">if</span> <span class="s2">&quot;sched&quot;</span> <span class="ow">in</span> <span class="n">optim_config</span><span class="p">:</span>
            <span class="n">scheduler_config</span> <span class="o">=</span> <span class="n">optim_config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;sched&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scheduler_config</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Check if caller provided optimizer name, default to Adam otherwise</span>
        <span class="n">optimizer_cls</span> <span class="o">=</span> <span class="n">optim_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_target_&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">optimizer_cls</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Try to get optimizer name for dynamic resolution, defaulting to Adam</span>
            <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">optim_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;adam&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isclass</span><span class="p">(</span><span class="n">optimizer_cls</span><span class="p">):</span>
            <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">optimizer_cls</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># resolve the class name (lowercase) from the class path if not provided</span>
            <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">optimizer_cls</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

        <span class="c1"># We are guaranteed to have lr since it is required by the argparser</span>
        <span class="c1"># But maybe user forgot to pass it to this function</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">optim_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Check if caller has optimizer kwargs, default to empty dictionary</span>
        <span class="k">if</span> <span class="s2">&quot;args&quot;</span> <span class="ow">in</span> <span class="n">optim_config</span><span class="p">:</span>
            <span class="n">optimizer_args</span> <span class="o">=</span> <span class="n">optim_config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;args&quot;</span><span class="p">)</span>
            <span class="n">optimizer_args</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">parse_optimizer_args</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">,</span> <span class="n">optimizer_args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">optimizer_args</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">optim_config</span><span class="p">)</span>

            <span class="c1"># Remove extra parameters from optimizer_args nest</span>
            <span class="c1"># Assume all other parameters are to be passed into optimizer constructor</span>
            <span class="n">optimizer_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">optimizer_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cls&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">optimizer_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Adaptive schedulers don&#39;t need `lr`</span>
        <span class="k">if</span> <span class="n">lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">optimizer_args</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>

            <span class="c1"># Actually instantiate the optimizer</span>
            <span class="k">if</span> <span class="n">optimizer_cls</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">get_optimizer</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">)</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_param_groups</span><span class="p">,</span> <span class="o">**</span><span class="n">optimizer_args</span><span class="p">)</span>

                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Optimizer config = </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">optimizer</span><span class="p">))</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>

            <span class="k">elif</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isclass</span><span class="p">(</span><span class="n">optimizer_cls</span><span class="p">):</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer_cls</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_param_groups</span><span class="p">,</span> <span class="o">**</span><span class="n">optimizer_args</span><span class="p">)</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Optimizer config = </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">optimizer</span><span class="p">))</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Attempt class path resolution</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">optimizer_cls</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">({</span><span class="s2">&quot;_target_&quot;</span><span class="p">:</span> <span class="n">optimizer_cls</span><span class="p">})</span>
                    <span class="n">optimizer_config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">lr</span><span class="p">}</span> <span class="k">if</span> <span class="n">lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
                    <span class="n">optimizer_config</span> <span class="o">|=</span> <span class="n">optimizer_args</span>

                    <span class="n">optimizer_instance</span> <span class="o">=</span> <span class="n">hydra</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">instantiate</span><span class="p">(</span>
                        <span class="n">optimizer_cls</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_param_groups</span><span class="p">,</span> <span class="o">**</span><span class="n">optimizer_config</span>
                    <span class="p">)</span>  <span class="c1"># type: DictConfig</span>

                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Optimizer config = </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">optimizer_instance</span><span class="p">))</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">optimizer_instance</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Could not instantiate class path - </span><span class="si">{</span><span class="n">optimizer_cls</span><span class="si">}</span><span class="s2"> with kwargs </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">optimizer_config</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

                    <span class="k">raise</span> <span class="n">e</span>

            <span class="c1"># Try to instantiate scheduler for optimizer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scheduler</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">prepare_lr_scheduler</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">,</span> <span class="n">scheduler_config</span><span class="o">=</span><span class="n">scheduler_config</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_dl</span>
            <span class="p">)</span>

            <span class="c1"># Return the optimizer with/without scheduler</span>
            <span class="c1"># This return allows multiple optimizers or schedulers to be created</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scheduler</span></div>

<div class="viewcode-block" id="ModelPT.setup_optimizer_param_groups"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.setup_optimizer_param_groups">[docs]</a>    <span class="k">def</span> <span class="nf">setup_optimizer_param_groups</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used to create param groups for the optimizer. As an example, this can be used to specify per-layer learning</span>
<span class="sd">        rates:</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            optim.SGD([</span>
<span class="sd">                        {&#39;params&#39;: model.base.parameters()},</span>
<span class="sd">                        {&#39;params&#39;: model.classifier.parameters(), &#39;lr&#39;: 1e-3}</span>
<span class="sd">                        ], lr=1e-2, momentum=0.9)</span>

<span class="sd">        See https://pytorch.org/docs/stable/optim.html for more information. By default, ModelPT will use</span>
<span class="sd">        self.parameters(). Override this method to add custom param groups.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">param_groups</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;parameters&quot;</span><span class="p">):</span>
            <span class="n">param_groups</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()}]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_param_groups</span> <span class="o">=</span> <span class="n">param_groups</span></div>

<div class="viewcode-block" id="ModelPT.configure_optimizers"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.configure_optimizers">[docs]</a>    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Configure optimizers and schedulers for training.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_optimization</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scheduler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span>

        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">],</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_scheduler</span><span class="p">]</span></div>

<div class="viewcode-block" id="ModelPT.train_dataloader"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.train_dataloader">[docs]</a>    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the training dataloader.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_dl</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_dl</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="ModelPT.val_dataloader"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.val_dataloader">[docs]</a>    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the validation dataloader.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validation_dl</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validation_dl</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="ModelPT.test_dataloader"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.test_dataloader">[docs]</a>    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the test dataloader.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_dl</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_dl</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="ModelPT.validation_epoch_end"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.validation_epoch_end">[docs]</a>    <span class="k">def</span> <span class="nf">validation_epoch_end</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Default DataLoader for Validation set which automatically supports multiple data loaders</span>
<span class="sd">        via `multi_validation_epoch_end`.</span>
<span class="sd">        If multi dataset support is not required, override this method entirely in base class.</span>
<span class="sd">        In such a case, there is no need to implement `multi_validation_epoch_end` either.</span>

<span class="sd">        .. note::</span>
<span class="sd">            If more than one data loader exists, and they all provide `val_loss`,</span>
<span class="sd">            only the `val_loss` of the first data loader will be used by default.</span>
<span class="sd">            This default can be changed by passing the special key `val_dl_idx: int`</span>
<span class="sd">            inside the `validation_ds` config.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        outputs: Single or nested list of tensor outputs from one or more data loaders.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A dictionary containing the union of all items from individual data_loaders, along with merged logs from all</span>
<span class="sd">        data loaders.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Case where we dont provide data loaders</span>
        <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="c1"># Case where we provide exactly 1 data loader</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="n">output_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_validation_epoch_end</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="k">if</span> <span class="n">output_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;log&quot;</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">output_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">),</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="k">return</span> <span class="n">output_dict</span>

        <span class="n">output_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;log&quot;</span><span class="p">:</span> <span class="p">{}}</span>

        <span class="c1"># The output is a list of list of dicts, outer list corresponds to dataloader idx</span>
        <span class="k">for</span> <span class="n">dataloader_idx</span><span class="p">,</span> <span class="n">val_outputs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
            <span class="c1"># Get prefix and dispatch call to multi epoch end</span>
            <span class="n">dataloader_prefix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_validation_dataloader_prefix</span><span class="p">(</span><span class="n">dataloader_idx</span><span class="p">)</span>
            <span class="n">dataloader_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_validation_epoch_end</span><span class="p">(</span><span class="n">val_outputs</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="n">dataloader_idx</span><span class="p">)</span>

            <span class="c1"># If result was not provided, generate empty dict</span>
            <span class="n">dataloader_logs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataloader_logs</span> <span class="ow">or</span> <span class="p">{}</span>  <span class="c1"># type: ignore</span>

            <span class="c1"># Perform `val_loss` resolution first (if provided outside logs)</span>
            <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;val_loss&quot;</span> <span class="ow">in</span> <span class="n">dataloader_logs</span> <span class="ow">and</span> <span class="s2">&quot;val_loss&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>  <span class="c1"># type: ignore</span>
                <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_dl_idx</span>
            <span class="p">):</span>
                <span class="n">output_dict</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataloader_logs</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]</span>  <span class="c1"># type: ignore</span>

            <span class="c1"># For every item in the result dictionary</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataloader_logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>  <span class="c1"># type: ignore</span>
                <span class="c1"># If the key is `log`</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="s2">&quot;log&quot;</span><span class="p">:</span>
                    <span class="c1"># Parse every element of the log, and attach the prefix name of the data loader</span>
                    <span class="n">log_dict</span> <span class="o">=</span> <span class="p">{}</span>

                    <span class="k">for</span> <span class="n">k_log</span><span class="p">,</span> <span class="n">v_log</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="c1"># If we are logging the metric, but dont provide it at result level,</span>
                        <span class="c1"># store it twice - once in log and once in result level.</span>
                        <span class="c1"># Also mark log with prefix name to avoid log level clash with other data loaders</span>
                        <span class="k">if</span> <span class="n">k_log</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_dl_idx</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
                            <span class="n">new_k_log</span> <span class="o">=</span> <span class="n">k_log</span>

                            <span class="c1"># Also insert duplicate key with prefix for ease of comparison / avoid name clash</span>
                            <span class="n">log_dict</span><span class="p">[</span><span class="n">dataloader_prefix</span> <span class="o">+</span> <span class="n">k_log</span><span class="p">]</span> <span class="o">=</span> <span class="n">v_log</span>

                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># Simply prepend prefix to key and save</span>
                            <span class="n">new_k_log</span> <span class="o">=</span> <span class="n">dataloader_prefix</span> <span class="o">+</span> <span class="n">k_log</span>

                        <span class="c1"># Store log value</span>
                        <span class="n">log_dict</span><span class="p">[</span><span class="n">new_k_log</span><span class="p">]</span> <span class="o">=</span> <span class="n">v_log</span>

                    <span class="c1"># Update log storage of individual data loader</span>
                    <span class="n">output_logs</span> <span class="o">=</span> <span class="n">output_dict</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span>  <span class="c1"># type: ignore</span>
                    <span class="n">output_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">log_dict</span><span class="p">)</span>

                    <span class="c1"># Update global log storage</span>
                    <span class="n">output_dict</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_logs</span>  <span class="c1"># type: ignore</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># If any values are stored outside &#39;log&#39;, simply prefix name and store</span>
                    <span class="n">new_k</span> <span class="o">=</span> <span class="n">dataloader_prefix</span> <span class="o">+</span> <span class="n">k</span>
                    <span class="n">output_dict</span><span class="p">[</span><span class="n">new_k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>  <span class="c1"># type: ignore</span>

        <span class="k">if</span> <span class="s2">&quot;log&quot;</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">output_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">),</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

        <span class="c1"># return everything else</span>
        <span class="k">return</span> <span class="n">output_dict</span></div>

<div class="viewcode-block" id="ModelPT.test_epoch_end"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.test_epoch_end">[docs]</a>    <span class="k">def</span> <span class="nf">test_epoch_end</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Default DataLoader for Test set which automatically supports multiple data loaders</span>
<span class="sd">        via `multi_test_epoch_end`.</span>
<span class="sd">        If multi dataset support is not required, override this method entirely in base class.</span>
<span class="sd">        In such a case, there is no need to implement `multi_test_epoch_end` either.</span>

<span class="sd">        .. note::</span>
<span class="sd">            If more than one data loader exists, and they all provide `test_loss`,</span>
<span class="sd">            only the `test_loss` of the first data loader will be used by default.</span>
<span class="sd">            This default can be changed by passing the special key `_test_dl_idx: int`</span>
<span class="sd">            inside the `test_ds` config.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        outputs: Single or nested list of tensor outputs from one or more data loaders.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A dictionary containing the union of all items from individual data_loaders, along with merged logs from all</span>
<span class="sd">        data loaders.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Case where we dont provide data loaders</span>
        <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="c1"># Case where we provide exactly 1 data loader</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="n">output_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_test_epoch_end</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="k">if</span> <span class="n">output_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;log&quot;</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">output_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">),</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="k">return</span> <span class="n">output_dict</span>

        <span class="n">output_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;log&quot;</span><span class="p">:</span> <span class="p">{}}</span>

        <span class="c1"># The output is a list of dicts, outer list corresponds to dataloader idx</span>
        <span class="k">for</span> <span class="n">dataloader_idx</span><span class="p">,</span> <span class="n">test_outputs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
            <span class="c1"># Get prefix and dispatch call to multi epoch end</span>
            <span class="n">dataloader_prefix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_test_dataloader_prefix</span><span class="p">(</span><span class="n">dataloader_idx</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multi_test_epoch_end</span><span class="p">(</span><span class="n">test_outputs</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="n">dataloader_idx</span><span class="p">)</span>

            <span class="c1"># If result was not provided, generate empty dict</span>
            <span class="n">dataloader_logs</span> <span class="o">=</span> <span class="n">dataloader_logs</span> <span class="ow">or</span> <span class="p">{}</span>  <span class="c1"># type: ignore</span>

            <span class="c1"># Perform `test_loss` resolution first (if provided outside logs)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="s2">&quot;test_loss&quot;</span> <span class="ow">in</span> <span class="n">dataloader_logs</span>
                <span class="ow">and</span> <span class="s2">&quot;test_loss&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">output_dict</span>  <span class="c1"># type: ignore</span>
                <span class="ow">and</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_dl_idx</span>
            <span class="p">):</span>  <span class="c1"># type: ignore</span>
                <span class="n">output_dict</span><span class="p">[</span><span class="s2">&quot;test_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataloader_logs</span><span class="p">[</span><span class="s2">&quot;test_loss&quot;</span><span class="p">]</span>  <span class="c1"># type: ignore</span>

            <span class="c1"># For every item in the result dictionary</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataloader_logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># If the key is `log`</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="s2">&quot;log&quot;</span><span class="p">:</span>
                    <span class="c1"># Parse every element of the log, and attach the prefix name of the data loader</span>
                    <span class="n">log_dict</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">for</span> <span class="n">k_log</span><span class="p">,</span> <span class="n">v_log</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="c1"># If we are logging the loss, but dont provide it at result level,</span>
                        <span class="c1"># store it twice - once in log and once in result level.</span>
                        <span class="c1"># Also mark log with prefix name to avoid log level clash with other data loaders</span>
                        <span class="k">if</span> <span class="n">k_log</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_dl_idx</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
                            <span class="n">new_k_log</span> <span class="o">=</span> <span class="n">k_log</span>

                            <span class="c1"># Also insert duplicate key with prefix for ease of comparison / avoid name clash</span>
                            <span class="n">log_dict</span><span class="p">[</span><span class="n">dataloader_prefix</span> <span class="o">+</span> <span class="n">k_log</span><span class="p">]</span> <span class="o">=</span> <span class="n">v_log</span>

                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># Simply prepend prefix to key and save</span>
                            <span class="n">new_k_log</span> <span class="o">=</span> <span class="n">dataloader_prefix</span> <span class="o">+</span> <span class="n">k_log</span>

                        <span class="n">log_dict</span><span class="p">[</span><span class="n">new_k_log</span><span class="p">]</span> <span class="o">=</span> <span class="n">v_log</span>

                    <span class="c1"># Update log storage of individual data loader</span>
                    <span class="n">output_logs</span> <span class="o">=</span> <span class="n">output_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="p">{})</span>  <span class="c1"># type: ignore</span>
                    <span class="n">output_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">log_dict</span><span class="p">)</span>

                    <span class="c1"># Update global log storage</span>
                    <span class="n">output_dict</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_logs</span>  <span class="c1"># type: ignore</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># If any values are stored outside &#39;log&#39;, simply prefix name and store</span>
                    <span class="n">new_k</span> <span class="o">=</span> <span class="n">dataloader_prefix</span> <span class="o">+</span> <span class="n">k</span>
                    <span class="n">output_dict</span><span class="p">[</span><span class="n">new_k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>  <span class="c1"># type: ignore</span>

        <span class="k">if</span> <span class="s2">&quot;log&quot;</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">output_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">),</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

        <span class="c1"># return everything else</span>
        <span class="k">return</span> <span class="n">output_dict</span></div>

<div class="viewcode-block" id="ModelPT.multi_validation_epoch_end"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.multi_validation_epoch_end">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">multi_validation_epoch_end</span><span class="p">(</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">object</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="kc">None</span><span class="p">],</span> <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds support for multiple validation datasets. Should be overridden by subclass, to obtain appropriate logs for</span>
<span class="sd">         each of the dataloaders.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        outputs: Same as that provided by LightningModule.validation_epoch_end() for a single dataloader.</span>
<span class="sd">        dataloader_idx: int representing the index of the dataloader.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A dictionary of values, optionally containing a sub-dict `log`, such that the values in the log will be</span>
<span class="sd">        pre-pended by the dataloader prefix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Multi data loader support has been enabled, but `multi_validation_epoch_end(outputs, dataloader_idx) &quot;</span>
            <span class="s2">&quot;has not been implemented.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;If you require multi data loader support for validation sets, please override this method.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;If you do not require multi data loader support, please instead override `validation_epoch_end(outputs).&quot;</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ModelPT.multi_test_epoch_end"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.multi_test_epoch_end">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">multi_test_epoch_end</span><span class="p">(</span><span class="n">outputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">object</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]],</span> <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds support for multiple test datasets. Should be overridden by subclass, to obtain appropriate logs for each</span>
<span class="sd">        of the dataloaders.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        outputs: Same as that provided by LightningModule.validation_epoch_end() for a single dataloader.</span>
<span class="sd">        dataloader_idx: int representing the index of the dataloader.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A dictionary of values, optionally containing a sub-dict `log`, such that the values in the log will be</span>
<span class="sd">        pre-pended by the dataloader prefix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Multi data loader support has been enabled, but `multi_test_epoch_end(outputs, dataloader_idx) has not &quot;</span>
            <span class="s2">&quot;been implemented.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;If you require multi data loader support for validation sets, please override this method.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;If you do not require multi data loader support, please instead override test_epoch_end(outputs).&quot;</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ModelPT.get_validation_dataloader_prefix"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.get_validation_dataloader_prefix">[docs]</a>    <span class="k">def</span> <span class="nf">get_validation_dataloader_prefix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get the name of one or more data loaders, which will be prepended to all logs.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_names</span><span class="p">[</span><span class="n">dataloader_idx</span><span class="p">]</span>  <span class="c1"># type: ignore</span></div>

<div class="viewcode-block" id="ModelPT.get_test_dataloader_prefix"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.get_test_dataloader_prefix">[docs]</a>    <span class="k">def</span> <span class="nf">get_test_dataloader_prefix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get the name of one or more data loaders, which will be prepended to all logs.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_names</span><span class="p">[</span><span class="n">dataloader_idx</span><span class="p">]</span>  <span class="c1"># type: ignore</span></div>

<div class="viewcode-block" id="ModelPT.load_part_of_state_dict"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.load_part_of_state_dict">[docs]</a>    <span class="k">def</span> <span class="nf">load_part_of_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">include</span><span class="p">,</span> <span class="n">exclude</span><span class="p">,</span> <span class="n">load_from_string</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load part of the state dict.&quot;&quot;&quot;</span>
        <span class="n">excluded_param_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># create dict</span>
        <span class="n">dict_to_load</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">should_add</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="ow">in</span> <span class="n">k</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">include</span><span class="p">)</span>
            <span class="c1"># except for if any string from exclude is present</span>
            <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">exclude</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">k</span><span class="p">:</span>
                    <span class="n">excluded_param_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">should_add</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="n">should_add</span><span class="p">:</span>
                <span class="n">dict_to_load</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="c1"># Restore checkpoint part into current model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">dict_to_load</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model checkpoint partially restored from </span><span class="si">{</span><span class="n">load_from_string</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">excluded_param_names</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The following parameters were excluded from loading from </span><span class="si">{</span><span class="n">load_from_string</span><span class="si">}</span><span class="s2"> : </span><span class="si">{</span><span class="n">excluded_param_names</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Make sure that this is what you wanted!&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModelPT.maybe_init_from_pretrained_checkpoint"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.maybe_init_from_pretrained_checkpoint">[docs]</a>    <span class="nd">@rank_zero_only</span>
    <span class="k">def</span> <span class="nf">maybe_init_from_pretrained_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">OmegaConf</span><span class="p">,</span> <span class="n">map_location</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a given model with the parameters obtained via specific config arguments. The state dict of the \</span>
<span class="sd">        provided model will be updated with `strict=False` setting to prevent requirement of exact model parameters \</span>
<span class="sd">        matching.</span>

<span class="sd">        Initializations</span>

<span class="sd">        init_from_mridc_model: Str path to a .mridc model, which will be instantiated in order to extract the state \</span>
<span class="sd">        dict.</span>

<span class="sd">        init_from_pretrained_model: Str name of a pretrained model checkpoint (obtained via cloud). The model will \</span>
<span class="sd">        be downloaded (or a cached copy will be used), instantiated and then its state dict will be extracted.</span>

<span class="sd">        init_from_ptl_ckpt: Str name of a Pytorch Lightning checkpoint file. It will be loaded and the state dict \</span>
<span class="sd">        will extract.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        cfg: The config used to instantiate the model. It needs only contain one of the above keys.</span>
<span class="sd">        map_location: str or torch.device() which represents where the intermediate state dict (from the pretrained \</span>
<span class="sd">        model or checkpoint) will be loaded.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;init_from_mridc_model&quot;</span><span class="p">,</span> <span class="s2">&quot;init_from_pretrained_model&quot;</span><span class="p">,</span> <span class="s2">&quot;init_from_ptl_ckpt&quot;</span><span class="p">]</span>
        <span class="n">arg_matches</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">cfg</span> <span class="ow">and</span> <span class="n">arg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">arg_matches</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># model weights do not need to be restored</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">arg_matches</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot pass more than one model initialization arguments to config!</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Found : </span><span class="si">{</span><span class="p">[</span><span class="n">args</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">arg_present</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">arg_matches</span><span class="p">)</span> <span class="k">if</span> <span class="n">arg_present</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;init_from_mridc_model&quot;</span> <span class="ow">in</span> <span class="n">cfg</span> <span class="ow">and</span> <span class="n">cfg</span><span class="o">.</span><span class="n">init_from_mridc_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
            <span class="k">with</span> <span class="n">open_dict</span><span class="p">(</span><span class="n">cfg</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">init_from_mridc_model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
                    <span class="n">model_path</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">init_from_mridc_model</span>  <span class="c1"># type: ignore</span>
                    <span class="c1"># Restore model</span>
                    <span class="n">restored_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_from</span><span class="p">(</span>
                        <span class="n">model_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init_strict&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                    <span class="p">)</span>
                    <span class="c1"># Restore checkpoint into current model</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">restored_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model checkpoint restored from mridc file with path : `</span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">`&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">init_from_mridc_model</span><span class="p">,</span> <span class="p">(</span><span class="n">DictConfig</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)):</span>  <span class="c1"># type: ignore</span>
                    <span class="n">model_load_dict</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">init_from_mridc_model</span>  <span class="c1"># type: ignore</span>
                    <span class="k">for</span> <span class="n">model_load_cfg</span> <span class="ow">in</span> <span class="n">model_load_dict</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                        <span class="n">model_path</span> <span class="o">=</span> <span class="n">model_load_cfg</span><span class="o">.</span><span class="n">path</span>
                        <span class="c1"># Restore model</span>
                        <span class="n">restored_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_from</span><span class="p">(</span>
                            <span class="n">model_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init_strict&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                        <span class="p">)</span>

                        <span class="n">include</span> <span class="o">=</span> <span class="n">model_load_cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;include&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">])</span>
                        <span class="n">exclude</span> <span class="o">=</span> <span class="n">model_load_cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;exclude&quot;</span><span class="p">,</span> <span class="p">[])</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">load_part_of_state_dict</span><span class="p">(</span>
                            <span class="n">restored_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">include</span><span class="p">,</span> <span class="n">exclude</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;mridc file with path `</span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">`&quot;</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid type: init_from_mridc_model is not a string or a dict!&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;init_from_pretrained_model&quot;</span> <span class="ow">in</span> <span class="n">cfg</span> <span class="ow">and</span> <span class="n">cfg</span><span class="o">.</span><span class="n">init_from_pretrained_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
            <span class="k">with</span> <span class="n">open_dict</span><span class="p">(</span><span class="n">cfg</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
                <span class="c1"># Restore model</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">init_from_pretrained_model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
                    <span class="n">model_name</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;init_from_pretrained_model&quot;</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

                    <span class="c1"># Check if model is being resumed or not - only works if `Trainer` is attached to model</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;trainer&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span>
                        <span class="k">if</span> <span class="p">(</span>
                            <span class="nb">hasattr</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s2">&quot;resume_from_checkpoint&quot;</span><span class="p">)</span>
                            <span class="ow">and</span> <span class="n">trainer</span><span class="o">.</span><span class="n">checkpoint_connector</span><span class="o">.</span><span class="n">resume_checkpoint_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="p">):</span>
                            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                                <span class="s2">&quot;Model training is being resumed via Pytorch Lightning.</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="s2">&quot;Initialization from pretrained model (via cloud) will be skipped.&quot;</span>
                            <span class="p">)</span>
                            <span class="k">return</span>

                    <span class="n">restored_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                        <span class="n">model_name</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init_strict&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                    <span class="p">)</span>

                    <span class="c1"># Restore checkpoint into current model</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">restored_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model checkpoint restored from pretrained checkpoint with name : `</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">`&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">init_from_pretrained_model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
                    <span class="k">pass</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">init_from_pretrained_model</span><span class="p">,</span> <span class="p">(</span><span class="n">DictConfig</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)):</span>  <span class="c1"># type: ignore</span>
                    <span class="n">model_load_dict</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">init_from_pretrained_model</span>  <span class="c1"># type: ignore</span>
                    <span class="k">for</span> <span class="n">model_load_cfg</span> <span class="ow">in</span> <span class="n">model_load_dict</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                        <span class="n">model_name</span> <span class="o">=</span> <span class="n">model_load_cfg</span><span class="o">.</span><span class="n">name</span>
                        <span class="c1"># Restore model</span>
                        <span class="n">restored_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                            <span class="n">model_name</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init_strict&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                        <span class="p">)</span>

                        <span class="n">include</span> <span class="o">=</span> <span class="n">model_load_cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;include&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">])</span>
                        <span class="n">exclude</span> <span class="o">=</span> <span class="n">model_load_cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;exclude&quot;</span><span class="p">,</span> <span class="p">[])</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">load_part_of_state_dict</span><span class="p">(</span>
                            <span class="n">restored_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                            <span class="n">include</span><span class="p">,</span>
                            <span class="n">exclude</span><span class="p">,</span>
                            <span class="sa">f</span><span class="s2">&quot;pretrained checkpoint with name `</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">`&quot;</span><span class="p">,</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid type: init_from_pretrained_model is not a string or a dict!&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;init_from_ptl_ckpt&quot;</span> <span class="ow">in</span> <span class="n">cfg</span> <span class="ow">and</span> <span class="n">cfg</span><span class="o">.</span><span class="n">init_from_ptl_ckpt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
            <span class="k">with</span> <span class="n">open_dict</span><span class="p">(</span><span class="n">cfg</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">init_from_ptl_ckpt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
                    <span class="c1"># Restore checkpoint</span>
                    <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;init_from_ptl_ckpt&quot;</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                    <span class="n">ckpt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">)</span>

                    <span class="c1"># Restore checkpoint into current model</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">],</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Model checkpoint restored from pytorch lightning checkpoint with path : `</span><span class="si">{</span><span class="n">ckpt_path</span><span class="si">}</span><span class="s2">`&quot;</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">init_from_ptl_ckpt</span><span class="p">,</span> <span class="p">(</span><span class="n">DictConfig</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)):</span>  <span class="c1"># type: ignore</span>
                    <span class="n">model_load_dict</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">init_from_ptl_ckpt</span>  <span class="c1"># type: ignore</span>
                    <span class="k">for</span> <span class="n">model_load_cfg</span> <span class="ow">in</span> <span class="n">model_load_dict</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                        <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">model_load_cfg</span><span class="o">.</span><span class="n">path</span>
                        <span class="c1"># Restore model</span>
                        <span class="n">ckpt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">)</span>

                        <span class="n">include</span> <span class="o">=</span> <span class="n">model_load_cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;include&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">])</span>
                        <span class="n">exclude</span> <span class="o">=</span> <span class="n">model_load_cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;exclude&quot;</span><span class="p">,</span> <span class="p">[])</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">load_part_of_state_dict</span><span class="p">(</span>
                            <span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">],</span> <span class="n">include</span><span class="p">,</span> <span class="n">exclude</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;nemo file with path `</span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">`&quot;</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid type: init_from_ptl_ckpt is not a string or a dict!&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModelPT.teardown"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.teardown">[docs]</a>    <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Called at the end of fit and test.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="s2">&quot;fit&quot;</span> <span class="ow">and</span> <span class="s2">&quot;PL_TRAINER_GPUS&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;PL_TRAINER_GPUS&quot;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">teardown</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModelPT.extract_state_dict_from"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.extract_state_dict_from">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">extract_state_dict_from</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">restore_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">save_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">split_by_module</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">save_restore_connector</span><span class="p">:</span> <span class="n">SaveRestoreConnector</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extract the state dict(s) from a provided .mridc tarfile and save it to a directory.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        restore_path: path to .mridc file from which state dict(s) should be extracted</span>
<span class="sd">        save_dir: directory in which the saved state dict(s) should be stored</span>
<span class="sd">        split_by_module: bool flag, which determines whether the output checkpoint should be for the entire Model, or</span>
<span class="sd">        the individual module&#39;s that comprise the Model</span>
<span class="sd">        save_restore_connector: Can be overridden to add custom save and restore logic.</span>

<span class="sd">        Example</span>
<span class="sd">        -------</span>
<span class="sd">        To convert the .mridc tarfile into a single Model level PyTorch checkpoint</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            state_dict = mridc.collections.asr.models.EncDecCTCModel.extract_state_dict_from(&#39;asr.mridc&#39;, \</span>
<span class="sd">            &#39;./asr_ckpts&#39;)</span>

<span class="sd">        To restore a model from a Model level checkpoint</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            model = mridc.collections.asr.models.EncDecCTCModel(cfg)  # or any other method of restoration</span>
<span class="sd">            model.load_state_dict(torch.load(&quot;./asr_ckpts/model_weights.ckpt&quot;))</span>

<span class="sd">        To convert the .mridc tarfile into multiple Module level PyTorch checkpoints</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            state_dict = mridc.collections.asr.models.EncDecCTCModel.extract_state_dict_from(&#39;asr.mridc&#39;, \</span>
<span class="sd">            &#39;./asr_ckpts&#39;, split_by_module=True)</span>

<span class="sd">        To restore a module from a Module level checkpoint</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            model = mridc.collections.asr.models.EncDecCTCModel(cfg)  # or any other method of restoration</span>
<span class="sd">            # load the individual components</span>
<span class="sd">            model.preprocessor.load_state_dict(torch.load(&quot;./asr_ckpts/preprocessor.ckpt&quot;))</span>
<span class="sd">            model.encoder.load_state_dict(torch.load(&quot;./asr_ckpts/encoder.ckpt&quot;))</span>
<span class="sd">            model.decoder.load_state_dict(torch.load(&quot;./asr_ckpts/decoder.ckpt&quot;))</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        The state dict that was loaded from the original .mridc checkpoint.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">save_restore_connector</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_restore_connector</span> <span class="o">=</span> <span class="n">SaveRestoreConnector</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">restore_path</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">FileExistsError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Can&#39;t find </span><span class="si">{</span><span class="n">restore_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">cls</span><span class="o">.</span><span class="n">update_save_restore_connector</span><span class="p">(</span><span class="n">save_restore_connector</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_save_restore_connector</span><span class="o">.</span><span class="n">extract_state_dict_from</span><span class="p">(</span><span class="n">restore_path</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">,</span> <span class="n">split_by_module</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModelPT.prepare_test"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.prepare_test">[docs]</a>    <span class="k">def</span> <span class="nf">prepare_test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;Trainer&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Helper method to check whether the model can safely be tested on a dataset after training (or loading a</span>
<span class="sd">        checkpoint).</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            trainer = Trainer()</span>
<span class="sd">            if model.prepare_test(trainer):</span>
<span class="sd">                trainer.test(model)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Bool which declares the model safe to test. Provides warnings if it has to return False to guide the user.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="s2">&quot;test_ds&quot;</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No `test_ds` config found within the manifest.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">trainer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">trainer</span><span class="o">.</span><span class="n">num_devices</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Replace ddp multi-gpu until PTL has a fix</span>
            <span class="n">DDP_WARN</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span><span class="se">\n\n</span><span class="s2">During testing, it is currently advisable to construct a new Trainer &quot;</span>
<span class="s2">                    &quot;with single GPU and no DDP to obtain accurate results.</span>
<span class="s2">                    &quot;Following pattern should be used: &quot;</span>
<span class="s2">                    &quot;trainer = Trainer(devices=1, accelerator=&#39;gpu&#39;)</span>
<span class="s2">                    &quot;if model.prepare_test(trainer):&quot;</span>
<span class="s2">                    &quot;  trainer.test(model)</span><span class="se">\n\n</span><span class="s2">&quot;&quot;&quot;</span>

            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">DDP_WARN</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Assign trainer to the model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_trainer</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="ModelPT.set_trainer"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.set_trainer">[docs]</a>    <span class="k">def</span> <span class="nf">set_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="n">Trainer</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set an instance of Trainer object.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span> <span class="o">=</span> <span class="n">trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_world_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModelPT.set_world_size"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.set_world_size">[docs]</a>    <span class="k">def</span> <span class="nf">set_world_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="n">Trainer</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Determines the world size from the PyTorch Lightning Trainer and then updates AppState.&quot;&quot;&quot;</span>
        <span class="c1"># Update AppState with world information from trainer</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">Trainer</span><span class="p">):</span>
            <span class="n">app_state</span> <span class="o">=</span> <span class="n">AppState</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">num_devices</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
                <span class="n">app_state</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">num_devices</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainer</span><span class="o">.</span><span class="n">num_nodes</span>  <span class="c1"># type: ignore</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;World size can only be set by PyTorch Lightning Trainer.&quot;</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_update_dataset_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">DictConfig</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]]):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the config (if not None) of the dataset by given name. Preserves said config after updating.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dataset_name: str name of the dataset whose config is being updated. Can be one of `train`, `validation` and</span>
<span class="sd">        `test`.</span>
<span class="sd">        config: Optional DictConfig or dict. If None is passed, this method simply returns. If dict is passed, it is</span>
<span class="sd">        cast into a DictConfig. The internal config is updated with the passed config.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_multi_dataset_mode&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_multi_dataset_mode</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">DictConfig</span><span class="p">):</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">dataset_name</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">}:</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

                <span class="n">key_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">_ds&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="p">[</span><span class="n">key_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span>

                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

                <span class="c1"># Update hyperparameters by calling property setter</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`dataset_name` when updating config must be one of [train, validation, test]&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Utility property that returns the total number of parameters of the Model.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cfg</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Property that holds the finalized internal config of the model.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Changes to this config are not reflected in the state of the model.</span>
<span class="sd">            Please create a new model using an updated config to properly update the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span>

    <span class="nd">@cfg</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">cfg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Property that holds the finalized internal config of the model.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Changes to this config are not reflected in the state of the model.</span>
<span class="sd">            Please create a new model using an updated config to properly update the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_hparams</span><span class="p">(</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">({</span><span class="s2">&quot;cfg&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">}))</span>

        <span class="c1"># TODO: Remove this when we have a better way to handle this</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_hparams_initial&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;cfg&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hparams_initial</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hparams_initial</span><span class="p">[</span><span class="s2">&quot;cfg&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_object</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_model_being_restored</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Checks if the model is being restored from a checkpoint.&quot;&quot;&quot;</span>
        <span class="n">app_state</span> <span class="o">=</span> <span class="n">AppState</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">app_state</span><span class="o">.</span><span class="n">is_model_being_restored</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_set_model_restore_state</span><span class="p">(</span><span class="n">is_being_restored</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">folder</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the state of the model to be restored.&quot;&quot;&quot;</span>
        <span class="n">app_state</span> <span class="o">=</span> <span class="n">AppState</span><span class="p">()</span>
        <span class="n">app_state</span><span class="o">.</span><span class="n">is_model_being_restored</span> <span class="o">=</span> <span class="n">is_being_restored</span>
        <span class="n">app_state</span><span class="o">.</span><span class="n">mridc_file_folder</span> <span class="o">=</span> <span class="n">folder</span>  <span class="c1"># type: ignore</span>

    <span class="k">def</span> <span class="nf">_set_model_guid</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the model guid.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;model_guid&quot;</span><span class="p">):</span>
            <span class="n">appstate</span> <span class="o">=</span> <span class="n">AppState</span><span class="p">()</span>

            <span class="c1"># Generate a unique uuid for the instance</span>
            <span class="c1"># also determine if the model is being restored or not, and preserve the path</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_guid</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_model_being_restored</span><span class="p">():</span>
                <span class="n">restore_path</span> <span class="o">=</span> <span class="n">appstate</span><span class="o">.</span><span class="n">model_restore_path</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">restore_path</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">appstate</span><span class="o">.</span><span class="n">register_model_guid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_guid</span><span class="p">,</span> <span class="n">restoration_path</span><span class="o">=</span><span class="n">restore_path</span><span class="p">)</span>

<div class="viewcode-block" id="ModelPT.update_save_restore_connector"><a class="viewcode-back" href="../../../../mridc.core.classes.html#mridc.core.classes.modelPT.ModelPT.update_save_restore_connector">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">update_save_restore_connector</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">save_restore_connector</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update the save_restore_connector of the model.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s2">&quot;_save_restore_connector&quot;</span><span class="p">):</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">_save_restore_connector</span> <span class="o">=</span> <span class="n">save_restore_connector</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s2">&quot;_save_restore_connector&quot;</span><span class="p">,</span> <span class="n">save_restore_connector</span><span class="p">)</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Dimitrios Karkalousos.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

</body>
</html>
