# coding=utf-8
# Automatically generated by Pynguin.
import mridc.core.classes.loss as module_0


def test_case_0():
    str_0 = "keep_eta"
    loss_0 = module_0.Loss()
    assert loss_0.training is True
    assert loss_0.reduction == "mean"
    loss_1 = module_0.Loss(str_0)
    assert loss_1.training is True
    assert loss_1.reduction == "mean"
    loss_2 = module_0.Loss(loss_1)
    assert loss_2.training is True
    assert loss_2.reduction == "mean"
    str_1 = None
    loss_3 = module_0.Loss(str_1)
    assert loss_3.training is True
    assert loss_3.reduction == "mean"
    str_2 = "d|\tCMGcn]5g"
    loss_4 = module_0.Loss(str_2)
    assert loss_4.training is True
    assert loss_4.reduction == "mean"
    loss_5 = module_0.Loss()
    assert loss_5.training is True
    assert loss_5.reduction == "mean"
    loss_6 = module_0.Loss()
    assert loss_6.training is True
    assert loss_6.reduction == "mean"
    bytes_0 = None
    str_3 = None
    str_4 = ""
    str_5 = "reg_model_architecture"
    list_0 = [str_5, str_3, str_1]
    loss_7 = module_0.Loss(list_0)
    assert loss_7.training is True
    assert loss_7.reduction == "mean"
    loss_8 = module_0.Loss(str_4)
    assert loss_8.training is True
    assert loss_8.reduction == "sum"
    loss_9 = module_0.Loss()
    assert loss_9.training is True
    assert loss_9.reduction == "mean"
    loss_10 = module_0.Loss(bytes_0, str_3)
    assert loss_10.training is True
    assert loss_10.reduction == "mean"
    loss_11 = module_0.Loss()
    assert loss_11.training is True
    assert loss_11.reduction == "mean"


def test_case_1():
    str_0 = "brain"
    str_1 = "I:1y"
    dict_0 = {str_0: str_1, str_1: str_1, str_1: str_0}
    loss_0 = module_0.Loss(dict_0)
    assert loss_0.training is True
    assert loss_0.reduction == "mean"
    loss_1 = module_0.Loss(loss_0)
    assert loss_1.training is True
    assert loss_1.reduction == "mean"
    dict_1 = {}
    bytes_0 = b"\xeb\xb5a<\xe1`\xe6Z\xce\x7f;Zb!\x94\xbb\xacE"
    loss_2 = module_0.Loss(dict_1, bytes_0)
    assert loss_2.training is True
    assert loss_2.reduction == "sum"
    loss_3 = module_0.Loss(str_0, str_1)
    assert loss_3.training is True
    assert loss_3.reduction == "mean"
    float_0 = 6.15
    loss_4 = module_0.Loss(float_0)
    assert loss_4.training is True
    assert loss_4.reduction == "mean"
    bytes_1 = None
    list_0 = [bytes_1, str_0, float_0, loss_4]
    int_0 = 39
    str_2 = ".7"
    loss_5 = module_0.Loss(list_0, int_0, str_2)
    assert loss_5.training is True
    assert loss_5.reduction == "mean"
    bool_0 = False
    loss_6 = module_0.Loss(str_1)
    assert loss_6.training is True
    assert loss_6.reduction == "mean"
    loss_7 = module_0.Loss()
    assert loss_7.training is True
    assert loss_7.reduction == "mean"
    loss_8 = module_0.Loss(str_0)
    assert loss_8.training is True
    assert loss_8.reduction == "mean"
    loss_9 = module_0.Loss(bool_0)
    assert loss_9.training is True
    assert loss_9.reduction == "sum"
    str_3 = """
    Adds two filehandlers to pytorch_lightning's logger. Called in mridc.utils.exp_manager(). The first filehandler
    logs all messages to all_log_file while the second filehandler logs all WARNING and higher messages to
    err_log_file. If "memory_err" and "memory_all" exist in HANDLERS, then those buffers are flushed to err_log_file
    and all_log_file respectively, and then closed.
    """
    loss_10 = module_0.Loss()
    assert loss_10.training is True
    assert loss_10.reduction == "mean"
    loss_11 = module_0.Loss(str_3)
    assert loss_11.training is True
    assert loss_11.reduction == "mean"
    loss_12 = module_0.Loss()
    assert loss_12.training is True
    assert loss_12.reduction == "mean"
    str_4 = """
    Helper method that operates on the ModelPT class to automatically support
    multiple dataloaders for the test set.
    It does so by first resolving the path to one/more data files via `resolve_dataset_name_from_cfg()`.
    If this resolution fails, it assumes the data loader is prepared to manually support / not support
    multiple data loaders and simply calls the appropriate setup method.
    If resolution succeeds:
        Checks if provided path is to a single file or a list of files.
        If a single file is provided, simply tags that file as such and loads it via the setup method.
        If multiple files are provided:
            Inject a new manifest path at index "i" into the resolved key.
            Calls the appropriate setup method to set the data loader.
            Collects the initialized data loader in a list and preserves it.
            Once all data loaders are processed, assigns the list of loaded loaders to the ModelPT.
            Finally, assigns a list of unique names resolved from the file paths to the ModelPT.

    Parameters
    ----------
    model: ModelPT subclass, which requires >=1 Test Dataloaders to be setup.
    """
    loss_13 = module_0.Loss(str_4)
    assert loss_13.training is True
    assert loss_13.reduction == "mean"
    dict_2 = {}
    loss_14 = module_0.Loss(loss_6)
    assert loss_14.training is True
    assert loss_14.reduction == "mean"
    loss_15 = module_0.Loss(bytes_0, str_4)
    assert loss_15.training is True
    assert loss_15.reduction == "mean"
    loss_16 = module_0.Loss()
    assert loss_16.training is True
    assert loss_16.reduction == "mean"
    loss_17 = module_0.Loss(dict_2)
    assert loss_17.training is True
    assert loss_17.reduction == "sum"
    loss_18 = module_0.Loss(bytes_0, str_4)
    assert loss_18.training is True
    assert loss_18.reduction == "mean"
    float_1 = 4.52
    loss_19 = module_0.Loss(dict_2)
    assert loss_19.training is True
    assert loss_19.reduction == "sum"
    loss_20 = module_0.Loss(float_1)
    assert loss_20.training is True
    assert loss_20.reduction == "mean"
    loss_21 = module_0.Loss()
    assert loss_21.training is True
    assert loss_21.reduction == "mean"
    loss_22 = module_0.Loss(str_3)
    assert loss_22.training is True
    assert loss_22.reduction == "mean"
